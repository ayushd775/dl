{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7c31b5-7352-42e6-ae65-a6df2e02d041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 02:05:51.434895: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-10 02:05:51.900872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-10 02:05:53.630392: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-10 02:05:53.630392: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9145 files belonging to 102 classes.\n",
      "Using 7316 files for training.\n",
      "Using 7316 files for training.\n",
      "Found 9145 files belonging to 102 classes.\n",
      "Using 1829 files for validation.\n",
      "Found 9145 files belonging to 102 classes.\n",
      "Using 1829 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 02:05:55.167311: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 02:05:56.115335: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2025-11-10 02:05:56.306299: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2025-11-10 02:05:56.745676: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2025-11-10 02:05:56.901660: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2025-11-10 02:05:56.745676: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2025-11-10 02:05:56.901660: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 205520896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 4.9740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 02:05:58.947396: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.0312 - loss: 4.7186 - val_accuracy: 0.1125 - val_loss: 4.5170\n",
      "Epoch 2/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.0312 - loss: 4.7186 - val_accuracy: 0.1125 - val_loss: 4.5170\n",
      "Epoch 2/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.1000 - loss: 4.3225 - val_accuracy: 0.1375 - val_loss: 4.2886\n",
      "Epoch 3/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.1000 - loss: 4.3225 - val_accuracy: 0.1375 - val_loss: 4.2886\n",
      "Epoch 3/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5s/step - accuracy: 0.0938 - loss: 4.0669 - val_accuracy: 0.0812 - val_loss: 4.2592\n",
      "Epoch 4/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5s/step - accuracy: 0.0938 - loss: 4.0669 - val_accuracy: 0.0812 - val_loss: 4.2592\n",
      "Epoch 4/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.1187 - loss: 3.8625 - val_accuracy: 0.1000 - val_loss: 4.1221\n",
      "Epoch 5/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.1187 - loss: 3.8625 - val_accuracy: 0.1000 - val_loss: 4.1221\n",
      "Epoch 5/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.1156 - loss: 3.7860 - val_accuracy: 0.1688 - val_loss: 3.9188\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.1156 - loss: 3.7860 - val_accuracy: 0.1688 - val_loss: 3.9188\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,326</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)            │        \u001b[38;5;34m52,326\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,871,668</span> (56.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,871,668\u001b[0m (56.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,326</span> (204.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,326\u001b[0m (204.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,654</span> (408.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m104,654\u001b[0m (408.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory('/home/ayush/Desktop/lp4/dataset/caltech-101-img',\n",
    "                                                 validation_split = 0.2 ,subset = 'training',seed = 123,image_size = (224,224),batch_size = 32 )\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory('/home/ayush/Desktop/lp4/dataset/caltech-101-img',\n",
    "                                                    validation_split = 0.2,subset = 'validation',seed = 123,\n",
    "                                                     image_size = (224,224),batch_size = 32\n",
    "                                                    )\n",
    "train_ds = train_ds.map(lambda x , y : (x/255.0 , y))\n",
    "val_ds = val_ds.map(lambda x,y : (x/255.0,y))\n",
    "\n",
    "\n",
    "train_ds = train_ds.take(10)  # only first 10 batches (~320 images)\n",
    "val_ds = val_ds.take(5)       # only first 5 batches (~160 images)\n",
    "\n",
    "base = VGG16(weights = '/home/ayush/Desktop/lp4/dataset/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "            include_top = False , input_shape = (224,224,3))\n",
    "base.trainable = False\n",
    "\n",
    "\n",
    "model = Sequential([base,GlobalAveragePooling2D(),Dense(102,activation = 'softmax')])\n",
    "\n",
    "model.compile(optimizer = 'adam' ,\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_ds,validation_data = val_ds,epochs = 5)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "#Object detection using Transfer Learning of CNN architectures for the given (image dataset\n",
    "#1) using the below steps:\n",
    "#a. Load in a pre-trained CNN model trained on a large dataset\n",
    "#b. Freeze parameters (weights) in model's lower convolutional layers\n",
    "#c. Add custom classifier with several layers of trainable parameters to model\n",
    "#d. Train classifier layers on training data available for task\n",
    "#e. Fine-tune hyper parameters and unfreeze more layers as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc27c3b-3e88-4917-9da0-0dc595a0318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version with better accuracy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Load full dataset (no .take() limitation)\n",
    "train_ds_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/home/ayush/Desktop/lp4/dataset/caltech-101-img',\n",
    "    validation_split=0.2, \n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_ds_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/home/ayush/Desktop/lp4/dataset/caltech-101-img',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Normalize\n",
    "train_ds_full = train_ds_full.map(lambda x, y: (x/255.0, y))\n",
    "val_ds_full = val_ds_full.map(lambda x, y: (x/255.0, y))\n",
    "\n",
    "# Load VGG16 base\n",
    "base_improved = VGG16(\n",
    "    weights='/home/ayush/Desktop/lp4/dataset/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_improved.trainable = False\n",
    "\n",
    "# Build improved model with additional layers and dropout\n",
    "model_improved = Sequential([\n",
    "    base_improved,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),  # Additional hidden layer\n",
    "    Dropout(0.5),                   # Dropout for regularization\n",
    "    Dense(102, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model_improved.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Training improved model with full dataset...\")\n",
    "print(f\"Training batches: {len(list(train_ds_full))}\")\n",
    "print(f\"Validation batches: {len(list(val_ds_full))}\")\n",
    "\n",
    "# Train with more epochs\n",
    "history = model_improved.fit(\n",
    "    train_ds_full,\n",
    "    validation_data=val_ds_full,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "model_improved.summary()\n",
    "\n",
    "print(\"\\n--- Accuracy Improvements ---\")\n",
    "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280111f-db65-449a-bb8f-ba2570d6a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Fine-tuning - Unfreeze some layers for even better accuracy\n",
    "print(\"Fine-tuning: Unfreezing last few layers of VGG16...\")\n",
    "\n",
    "# Unfreeze the last 4 layers of VGG16\n",
    "base_improved.trainable = True\n",
    "for layer in base_improved.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate for fine-tuning\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_improved.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # Lower learning rate\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Trainable layers: {sum([1 for layer in model_improved.layers if layer.trainable])}\")\n",
    "print(f\"Non-trainable layers: {sum([1 for layer in model_improved.layers if not layer.trainable])}\")\n",
    "\n",
    "# Fine-tune with few more epochs\n",
    "history_finetune = model_improved.fit(\n",
    "    train_ds_full,\n",
    "    validation_data=val_ds_full,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "print(\"\\n--- After Fine-tuning ---\")\n",
    "print(f\"Final Training Accuracy: {history_finetune.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history_finetune.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b6242-3967-4af0-b7e7-1ce7616c71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy (Initial Training)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss (Initial Training)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare: Cell 1 vs Improved Model\n",
    "print(\"\\n=== COMPARISON ===\")\n",
    "print(f\"Cell 1 (Limited data, 5 epochs):     ~24% validation accuracy\")\n",
    "print(f\"Cell 2 (Full data, 10 epochs):       {history.history['val_accuracy'][-1]*100:.2f}% validation accuracy\")\n",
    "if 'history_finetune' in globals():\n",
    "    print(f\"Cell 3 (Fine-tuned):                  {history_finetune.history['val_accuracy'][-1]*100:.2f}% validation accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
